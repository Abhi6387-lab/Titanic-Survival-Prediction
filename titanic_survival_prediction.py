# -*- coding: utf-8 -*-
"""TITANIC SURVIVAL PREDICTION

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a6aMjCytRnxvLRFTWL53cciRH7U_QDn8
"""

# importing Necessary Libray

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

test_data = pd.read_csv('/content/Titanic-Dataset.csv')

test_data.shape

test_data.head()

test_data.info()

test_data.describe()

test_data.isnull().sum()

#droping unnecessary columns which we dont need

#droping cobin bcz it is having too much missing values
test_data = test_data.drop(['Cabin'],axis=1)

test_data = test_data.drop(['PassengerId','Name','Ticket'],axis=1)

print(test_data.columns)

#Filling missing'Age' with median value
test_data['Age'] = test_data['Age'].fillna(test_data['Age'].median())

#Filling missing 'Embarked' with mode(most common value)
test_data['Embarked'] = test_data['Embarked'].fillna(test_data['Embarked'].mode()[0])

test_data.isnull().sum()

test_data.info()

#changing Sex column object data type into int so that we can do ml opreations further
mapping = {'male':1,'female':0}
test_data['Sex'] = test_data['Sex'].map(mapping)

#changing Embarked column object data type into int so that we can do ml operations further
mapping = {'C':0, 'Q':1, 'S':2}
test_data['Embarked'] = test_data['Embarked'].map(mapping)

test_data.info()

test_data.head()

sns.countplot(x='Survived',data=test_data)
plt.title('Survival Count')
plt.xticks([0,1],['Not Survived','Survived'])
plt.show()

sns.countplot(x='Pclass', hue='Survived', data=test_data)
plt.title('Survival by Passenger Class')
plt.legend(title='Survived', labels=['No', 'Yes'])
plt.show()

sns.countplot(x='Sex', hue='Survived', data=test_data)
plt.title('Survival by Sex')
plt.legend(title='Survived', labels=['No', 'Yes'])
plt.show()

sns.histplot(test_data['Age'], kde=True, bins=30)
plt.title('Age Distribution of Passengers')
plt.xlabel('Age')
plt.show()

sns.histplot(x='Survived', y='Fare', data=test_data)
plt.title('Fare Paid vs. Survival')
plt.xticks([0,1],['Did not Survived','Survived'])
plt.show()

test_data.info()

from sklearn.model_selection import train_test_split

#Split the data into Train and Test Sets

x = test_data.drop('Survived',axis=1)
y = test_data['Survived']

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LogisticRegression
model = LogisticRegression(max_iter=1000)
model.fit(x_train, y_train)

y_pred = model.predict(x_test)

print(y_pred)

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

print("Accuracy:",accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

#create confusion matrix
cm = confusion_matrix(y_test, y_pred)

#plot heatmap
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Survived', 'Survived'], yticklabels=['Not Survived', 'Survived'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()